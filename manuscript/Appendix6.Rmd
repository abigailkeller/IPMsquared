---
title: "Appendix 6: Robustness Assessments"
output: pdf_document
---
# Appendix 6

To assess model performance and robustness, we conducted both a model selection and model checking procedure. For model selection, we evaluated multiple functional forms for describing the overwinter mortality using Watanabe–Akaike information criterion (WAIC). To check the model, we calculated posterior predictive p-values.

## Appendix 6.1

The inter-annual population transitions (i.e., transition from year $y$ to year $y+1$) are largely described by density-dependent overwinter mortality. Since density dependence only enters the model during this process and is therefore likely influential for forecasting the stable size distribution, we compared multiple functional forms for size- and density-dependent overwinter mortality (Equation 9 in main text).

We fit four separate models that are identical, apart from the functional form of overwinter survival (Equation 9). These models varied by whether the relationship between size- and density-dependence is additive or interactive, as well as how rapidly mortality decreases with size.

**Model 1:** interactive density- and size-dependence, steeper mortality decrease with size

$$
S_o(x,N^T_{t_\text{max},y}) = \text{exp}(-(\frac{\alpha_y^o \times N^T_{t_\text{max},y}}{x^2}) + \epsilon_y)
$$

**Model 2:** interactive density- and size-dependence, less steep mortality decrease with size

$$
S_o(x,N^T_{t_\text{max},y}) = \text{exp}(-(\frac{\alpha_y^o \times N^T_{t_\text{max},y}}{x}) + \epsilon_y)
$$

**Model 3:** additive density- and size-dependence, steeper mortality decrease with size

$$
S_o(x,N^T_{t_\text{max},y}) = \text{exp}(-(\frac{\alpha^o}{N^T_{t_\text{max},y}} + \frac{\psi}{x^2} + \epsilon_y))
$$

**Model 4:** additive density- and size-dependence, less steep mortality decrease with size

$$
S_o(x,N^T_{t_\text{max},i}) = \text{exp}(-(\frac{\alpha^o}{N^T_{t_\text{max},y}} + \frac{\psi}{x} + \epsilon_y))
$$

WAIC was calculated using every 10th sample from the combined posterior samples from four chains (3200 total samples). Model 1, with a size- and density-dependent overwinter mortality interaction and a steeper mortality decrease with size had the lowest WAIC and was used in subsequent analyses.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(kableExtra)
library(knitr)
df <- data.frame(
  Model = c("Model 1", "Model 2", "Model 3", "Model 4"),
  WAIC = c(6770.58, 6776.48, 6798.78, 7110.42),
  lppd = c(-3337.77, -3339.54, -3347.65, -3469.85),
  pWAIC = c(47.52, 48.70, 51.74, 85.36)
) %>% 
  mutate(delta_AIC = WAIC - min(WAIC))
colnames(df) <- c("Model", "WAIC", "lppd", "pWAIC", "$\\Delta$WAIC")

```

```{r, echo = FALSE}
# Render table
knitr::kable(
  df
)
```

## Appendix 6.2

Bayesian model checking was used to determine if the model is an adequate representation of the observed data. Fit was checked with an omnibus discrepancy function, deviance. Here, $D$ refers to the the count of removed crabs, $C_{t,j,y}(x_i)$ in the multi-year time-series data set (D1), the total number of removed crabs, $C^T_{t,i}(x_i)$ in the multi-year time-series data set (D1), the number of recaptured marked crabs, $r_t^{\text{mc}}(x_i)$ in the mark-recapture data set (D3), and the size of crabs in the size-at-age dataset (D2):

$$
T(D, \theta) = -2\text{log}(D|\theta)
$$

as well as a targeted discrepancy function to check zero inflation in the count data. Here, $D$ refers to the the count of removed crabs, $C(x)_{t,j,y}$:

$$
T(D) = \sum_iI(D_i = 0)
$$

**Generating posterior predictive samples and calculating deviance**

The posterior predictive samples (PPS) and deviance of PPS was calculated using the following nimble function:

```{r, eval = FALSE}
library(nimble)

ppSamplerNF <- nimbleFunction(
  setup = function(model, samples) {
    
    # theta
    topNodes <- model$getNodeNames(stochOnly = TRUE, topOnly = TRUE)
    
    # nodes to simulate
    simNodes <- model$getNodeNames()[!(model$getNodeNames() %in% topNodes)]
    
    # data nodes
    dataNodes <- model$getNodeNames(dataOnly = TRUE)
    
    n <- length(model$expandNodeNames(dataNodes, returnScalarComponents = TRUE))
    vars <- colnames(samples[, topNodes])
    
    # subset posterior samples to just theta (top nodes in graph)
    samples_sub <- samples[, topNodes]
    
  },
  run = function(samples = double(2)) {
    
    nSamp <- dim(samples)[1]
    ppSamples <- matrix(nrow = nSamp, ncol = n + 1)
    
    for(i in 1:nSamp) {
      
      # add theta to model
      values(model, vars) <<- samples_sub[i, ]
      
      # update nodes based on theta
      model$simulate(simNodes, includeData = TRUE)
      
      # save PPS
      ppSamples[i, 1:n] <- values(model, dataNodes)
      
      # store deviance of each sample
      ppSamples[i, n + 1] <- 2 * model$calculate(dataNodes)
    }
    returnType(double(2))
    return(ppSamples)
  })
```

The posterior predictive samples (PPS) and deviance were calculated and saved using the nimble function:

```{r, eval = FALSE}
# generate posterior predictive sampler
ppSampler <- ppSamplerNF(
  myModel, # uncompiled model (see Appendix 3)
  samples # posterior samples
)

# compile posterior predictive samples
cppSampler <- compileNimble(
  ppSampler, 
  project = CmyModel # compiled model (see Appendix 3)
)

# run compiled function
ppSamples_via_nf <- cppSampler$run(samples)

# get PPS and samples
dataNodes <- myModel$getNodeNames(dataOnly = TRUE)
n <- length(CmyModel$expandNodeNames(dataNodes, returnScalarComponents = TRUE))
node_names <- myModel$expandNodeNames(dataNodes, returnScalarComponents = TRUE)
ppSamples <- ppSamples_via_nf[, 1:n]
deviance <- ppSamples_via_nf[, n + 1]

# save PPS (break up into smaller dfs)
for (i in 1:14) {
  temp <- grep(paste0("n_C\\[", i, ", "), node_names)
  saveRDS(node_names[temp], 
          paste0("data/posterior_predictive_check/node_names_",i,".rds"))
  saveRDS(ppSamples_via_nf[, temp],
          paste0("data/posterior_predictive_check/PPS_",i,".rds"))
}

# save deviance
saveRDS(deviance, "data/posterior_predictive_check/deviance_yrep.rds")
```

**Calculating deviance of data**

Bayesian p-values are calculated by comparing the deviance of the posterior predictive samples and the deviance of the observed data. Deviance of the data was calculated using the following nimble function:

```{r, eval = FALSE}
calc_deviance_D <- nimbleFunction(
  setup = function(model, samples) {
    
    # theta = top nodes and latent states
    theta <- colnames(samples)
    
    # calculate model graph dependencies of theta to update
    deps <- model$getDependencies(theta, self = TRUE)
    
    # data nodes
    dataNodes <- model$getNodeNames(dataOnly = TRUE)
    
  },
  run = function(samples = double(2)) {
    
    nSamp <- dim(samples)[1]
    deviance <- rep(NA, nSamp)
    
    for(i in 1:nSamp) {
      
      # add theta
      values(model, theta) <<- samples[i, ]
      
      # update dependencies
      model$calculate(deps)
      
      # calculate deviance
      deviance[i] <- 2 * model$calculate(dataNodes)
    }
    returnType(double(1))
    return(deviance)
  })
```

The deviance of the data was calculated and saved using the nimble function:

```{r, eval = FALSE}
# generate deviance calculator
devianceCalculator <- calc_deviance_y(
  myModel, # uncompiled model, contains data (see Appendix 3)
  samples # posterior samples
)

# compile deviance calculator
CdevianceCalculator <- compileNimble(
  devianceCalculator, 
  project = CmyModel # compiled model, contains data (see Appendix 3)
)

# run compiled function
data_deviance_via_nf <- CdevianceCalculator$run(samples)

# save
saveRDS(data_deviance_via_nf, "data/posterior_predictive_check/deviance_y.rds")
```

\newpage

**Model checking with deviance**

The Bayesian p-value calculated using deviance as the proportion of $T(y_i) > T(y^{rep}_i)$. The deviance p-value is 0.92. 

**Figure A6.1:** Histogram of deviance generated for each posterior sample for $y$ (red) and $y^{rep}$ (blue).

```{r, echo=FALSE}
knitr::include_graphics(
  paste0("C:/Users/abiga/Documents/Berkeley/Structured_Decision_Making/",
         "pop_dynamics_model/IPMsquared/figures/ppp_deviance_plot.png")
)
```

\newpage

**Model checked with zero inflation**

The Bayesian p-value using the targeted zero-inflation check was calculated as the proportion of $T(y_i) > T(y^{rep}_i)$, where $y$ refers to the count data. The zero-inflation check p-value is 0.92. 

**Figure A6.2:** Histogram of proportion of zeros in each set, $i$, of posterior predictive samples, $y^{rep}$. Red line indicates the proportion of zeros in the count data, $y$.

```{r, echo=FALSE}
knitr::include_graphics(
  paste0("C:/Users/abiga/Documents/Berkeley/Structured_Decision_Making/",
         "pop_dynamics_model/IPMsquared/figures/ppp_zeros.png")
)
```

## Seadrift Lagoon

Here we describe the batch mark-recapture data (D3). The data was taken from Grosholz et al. 2021, where the co-authors conducted an extensive capture-mark-recapture experiment to estimate population size at Seadrift Lagoon in California, USA (Grosholz et al. 2021).

The authors deployed 15 Fukui traps in June within the lagoon. Over the succeeding three days, they marked all crabs caught by clipping two spines on the carapace, recording their size, and releasing them back to their original location. Within successive weeks as part of an eradication program, crabs were removed, and the number and carapace width of retrieved (marked and unmarked) crabs were recorded.

Data was retrieved from NSF’s Biological and Chemical Oceanography Data Management Office at https://www.bco-dmo.org/person/699768. While the mark-recapture experiment took place from 2011-2018, we only used data from one year, 2011, since the marking data was unambiguous.

The batch mark-recapture data consists of 1) the count of marked and released crabs of discrete size $x_i$ in the first time period, $n^{\text{mc}}(x_i)$, and 2) the count of recaptured and marked crabs of discrete size $x_i$ in the second time period, $m^{\text{mc}}(x_i)$. These data follow a binomial distribution:

$$
m^{\text{mc}}(x_i) \sim \text{Binomial}(n^{\text{mc}}_{t_2}(x_i), p^{\text{mc}}(x_i)) 
$$

where $p^{\text{mc}}(x_i)$ is the total probability of capture based on the total number of Fukui traps set, $O^{\text{mc}}$, over the time period $\Delta b^{\text{mc}}$:

$$
p^{\text{mc}}(x) = 1-\text{exp}\left(-\sum_{j=1}^{O^{\text{mc}}} H_{F,j}(x)\Delta b^{\text{mc}}_j\right)
$$

These data also informed components of the growth and natural mortality kernel (Table 1; Figure 2). The number of marked and released crabs, $n^{\text{mc}}(x_i)$, at $t_1^{\text{mc}}$ underwent seasonal growth and natural mortality to the next time period, $t_2^{\text{mc}}$.

$$
n^{\text{mc}}_{t_2}(x') = \int_{x \in \Omega} K^{mc}(x',x) n^{\text{mc}}_{t_1}(x)dx
$$




